{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/rds/general/user/mc4117/home/WeatherBench/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {\n",
    "    'geopotential': ('z', [500]),\n",
    "    'temperature': ('t', [850]),\n",
    "    'constants': ['orography']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [xr.open_mfdataset(f'{DATADIR}/{var}/*.nc', combine='by_coords') for var in var_dict.keys()]\n",
    "ds_whole = xr.merge(ds, compat = 'override')\n",
    "\n",
    "# load all training data\n",
    "ds_train = ds_whole.sel(time=slice('2015', '2016'))\n",
    "ds_test = ds_whole.sel(time=slice('2017', '2018'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, ds, var_dict, lead_time, batch_size=32, shuffle=True, load=True,\n",
    "                 mean=None, std=None, bins_z = None, output_vars=None):\n",
    "        \"\"\"\n",
    "        Data generator for WeatherBench data.\n",
    "        Template from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "        Args:\n",
    "            ds: Dataset containing all variables\n",
    "            var_dict: Dictionary of the form {'var': level}. Use None for level if data is of single level\n",
    "            lead_time: Lead time in hours\n",
    "            batch_size: Batch size\n",
    "            shuffle: bool. If True, data is shuffled.\n",
    "            load: bool. If True, datadet is loaded into RAM.\n",
    "            mean: If None, compute mean from data.\n",
    "            std: If None, compute standard deviation from data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.ds = ds\n",
    "        self.var_dict = var_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lead_time = lead_time\n",
    "\n",
    "        data = []\n",
    "        level_names = []\n",
    "        generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "        for long_var, params in var_dict.items():\n",
    "            if long_var == 'constants':\n",
    "                for var in params:\n",
    "                    data.append(ds[var].expand_dims(\n",
    "                        {'level': generic_level, 'time': ds.time}, (1, 0)\n",
    "                    ))\n",
    "                    level_names.append(var)\n",
    "            else:\n",
    "                var, levels = params\n",
    "                try:\n",
    "                    data.append(ds[var].sel(level=levels))\n",
    "                    level_names += [f'{var}_{level}' for level in levels]\n",
    "                except ValueError:\n",
    "                    data.append(ds[var].expand_dims({'level': generic_level}, 1))\n",
    "                    level_names.append(var)\n",
    "\n",
    "        self.data = xr.concat(data, 'level').transpose('time', 'lat', 'lon', 'level')\n",
    "        self.data['level_names'] = xr.DataArray(\n",
    "            level_names, dims=['level'], coords={'level': self.data.level})\n",
    "        if output_vars is None:\n",
    "            self.output_idxs = range(len(dg_valid.data.level))\n",
    "        else:\n",
    "            self.output_idxs = [i for i, l in enumerate(self.data.level_names.values)\n",
    "                                if any([bool(re.match(o, l)) for o in output_vars])]\n",
    "\n",
    "        output_data = self.data.isel(level = self.output_idxs)\n",
    "\n",
    "        # Normalize\n",
    "        self.mean = self.data.mean(('time', 'lat', 'lon')).compute() if mean is None else mean\n",
    "        self.std = self.data.std(('time', 'lat', 'lon')).compute() if std is None else std\n",
    "        self.data = (self.data - self.mean) / self.std\n",
    "\n",
    "        self.bins_z = np.linspace(output_data.min(), output_data.max(), 100) if bins_z is None else bins_z\n",
    "\n",
    "        self.binned_data = xr.DataArray(\n",
    "               np.digitize(output_data[:, :, :, 0], self.bins_z)-1,\n",
    "               dims=['time', 'lat', 'lon'],\n",
    "               coords={'time':self.data.time.values, 'lat': self.data.lat.values, 'lon': self.data.lon.values\n",
    "               })\n",
    "\n",
    "        del ds\n",
    "        \n",
    "        self.n_samples = self.data.isel(time=slice(0, -lead_time)).shape[0]\n",
    "        self.init_time = self.data.isel(time=slice(None, -lead_time)).time\n",
    "        self.valid_time = self.data.isel(time=slice(lead_time, None)).time   \n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "        # For some weird reason calling .load() earlier messes up the mean and std computations\n",
    "        if load: print('Loading data into RAM'); self.data.load()\n",
    "        if load: print('Loading data into RAM'); self.binned_data.load() \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.n_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        'Generate one batch of data'\n",
    "        idxs = self.idxs[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "        X = self.data.isel(time=idxs).values\n",
    "        y = self.binned_data.isel(time=idxs + self.lead_time).values\n",
    "        return X, y   \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.idxs = np.arange(self.n_samples)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.idxs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into RAM\n",
      "Loading data into RAM\n",
      "Loading data into RAM\n",
      "Loading data into RAM\n",
      "Loading data into RAM\n",
      "Loading data into RAM\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "bs=32\n",
    "lead_time=72\n",
    "output_vars = ['z_500']\n",
    "\n",
    "# Create a training and validation data generator. Use the train mean and std for validation as well.\n",
    "dg_train = DataGenerator(\n",
    "    ds_train.sel(time=slice('2015', '2015')), var_dict, lead_time, batch_size=bs, load=True, output_vars = output_vars)\n",
    "dg_valid = DataGenerator(\n",
    "    ds_train.sel(time=slice('2016', '2016')), var_dict, lead_time, batch_size=bs, mean=dg_train.mean, std=dg_train.std, shuffle=False, bins_z = dg_train.bins_z, output_vars = output_vars)\n",
    "\n",
    "# Now also a generator for testing. Impartant: Shuffle must be False!\n",
    "dg_test = DataGenerator(ds_test, var_dict, lead_time, batch_size=bs, mean=dg_train.mean, std=dg_train.std, bins_z = dg_train.bins_z,\n",
    "                         shuffle=False, output_vars=output_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 16, 32, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 16, 32, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 16, 32, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 18, 34, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 8, 16, 64)    0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 8, 16, 64)    4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 8, 16, 64)    256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 8, 16, 64)    0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 8, 16, 64)    36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 8, 16, 64)    256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 8, 16, 64)    0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 8, 16, 256)   16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 8, 16, 256)   16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 8, 16, 256)   1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 8, 16, 256)   1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 8, 16, 256)   0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 8, 16, 256)   0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 8, 16, 64)    16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 8, 16, 64)    256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 8, 16, 64)    0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 8, 16, 64)    36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 8, 16, 64)    256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 8, 16, 64)    0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 8, 16, 256)   16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 8, 16, 256)   1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 8, 16, 256)   0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 8, 16, 256)   0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 8, 16, 64)    16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 8, 16, 64)    256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 8, 16, 64)    0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 8, 16, 64)    36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 8, 16, 64)    256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 8, 16, 64)    0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 8, 16, 256)   16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 8, 16, 256)   1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 8, 16, 256)   0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 8, 16, 256)   0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 4, 8, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 4, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 4, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 4, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 4, 8, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 4, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 4, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 4, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 4, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 4, 8, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 4, 8, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 4, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 4, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 4, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 4, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 4, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 4, 8, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 4, 8, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 4, 8, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 4, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 4, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 4, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 4, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 4, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 4, 8, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 4, 8, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 4, 8, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 4, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 4, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 4, 8, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 4, 8, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 2, 4, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 2, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 2, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 2, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 2, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 2, 4, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 2, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 2, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 2, 4, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 2, 4, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 2, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 2, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 2, 4, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 2, 4, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 2, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 2, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 2, 4, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 2, 4, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 2, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 2, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 2, 4, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 2, 4, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 2, 4, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 2, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 2, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 2, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 2, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 2, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 2, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 2, 4, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 2, 4, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 1, 2, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 1, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 1, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 1, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 1, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 1, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 1, 2, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 1, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 1, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 1, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 1, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 1, 2, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 1, 2, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 1, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 1, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 1, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 1, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 1, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 1, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 1, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 1, 2, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 1, 2, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicPadding2D(keras.layers.Layer):\n",
    "    def __init__(self, pad_width, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pad_width = pad_width\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if self.pad_width == 0:\n",
    "            return inputs\n",
    "        inputs_padded = tf.concat(\n",
    "            [inputs[:, :, -self.pad_width:, :], inputs, inputs[:, :, :self.pad_width, :]], axis=2)\n",
    "        # Zero padding in the lat direction\n",
    "        inputs_padded = tf.pad(inputs_padded, [[0, 0], [self.pad_width, self.pad_width], [0, 0], [0, 0]])\n",
    "        return inputs_padded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'pad_width': self.pad_width})\n",
    "        return config\n",
    "\n",
    "\n",
    "class PeriodicConv2D(keras.layers.Layer):\n",
    "    def __init__(self, filters,\n",
    "                 kernel_size,\n",
    "                 conv_kwargs={},\n",
    "                 **kwargs, ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv_kwargs = conv_kwargs\n",
    "        if type(kernel_size) is not int:\n",
    "            assert kernel_size[0] == kernel_size[1], 'PeriodicConv2D only works for square kernels'\n",
    "            kernel_size = kernel_size[0]\n",
    "        pad_width = (kernel_size - 1) // 2\n",
    "        self.padding = PeriodicPadding2D(pad_width)\n",
    "        self.conv = Conv2D(\n",
    "            filters, kernel_size, padding='valid', **conv_kwargs\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.conv(self.padding(inputs))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({'filters': self.filters, 'kernel_size': self.kernel_size, 'conv_kwargs': self.conv_kwargs})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = resnet_model.output\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "x = Reshape((32, 64, 1))(x)\n",
    "x = PeriodicConv2D(100, 5)(x)\n",
    "x = LeakyReLU()(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = PeriodicConv2D(100, 5)(x)\n",
    "x = LeakyReLU()(x)\n",
    "#x = BatchNormalization()(x)\n",
    "out = Reshape((32*64, 100), input_shape = (32, 64, 100))(x)\n",
    "out = Activation('softmax')(out)\n",
    "predictions = Reshape((32, 64, 100), input_shape = (32*64, 100))(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 272 steps, validate for 273 steps\n",
      "Epoch 1/100\n",
      "272/272 [==============================] - 2731s 10s/step - loss: 2.0249 - sparse_categorical_accuracy: 0.2898 - val_loss: 3.7397 - val_sparse_categorical_accuracy: 0.1254\n",
      "Epoch 2/100\n",
      "272/272 [==============================] - 2790s 10s/step - loss: 1.9903 - sparse_categorical_accuracy: 0.2982 - val_loss: 3.8189 - val_sparse_categorical_accuracy: 0.1269\n",
      "Epoch 3/100\n",
      "271/272 [============================>.] - ETA: 7s - loss: 1.9594 - sparse_categorical_accuracy: 0.3057 \n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "272/272 [==============================] - 2665s 10s/step - loss: 1.9594 - sparse_categorical_accuracy: 0.3057 - val_loss: 3.8873 - val_sparse_categorical_accuracy: 0.1262\n",
      "Epoch 4/100\n",
      "272/272 [==============================] - 2334s 9s/step - loss: 1.9120 - sparse_categorical_accuracy: 0.3214 - val_loss: 3.8788 - val_sparse_categorical_accuracy: 0.1268\n",
      "Epoch 5/100\n",
      "271/272 [============================>.] - ETA: 6s - loss: 1.8972 - sparse_categorical_accuracy: 0.3258 \n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "272/272 [==============================] - 2184s 8s/step - loss: 1.8973 - sparse_categorical_accuracy: 0.3257 - val_loss: 3.9151 - val_sparse_categorical_accuracy: 0.1261\n",
      "Epoch 6/100\n",
      "272/272 [==============================] - 2039s 7s/step - loss: 1.8872 - sparse_categorical_accuracy: 0.3293 - val_loss: 3.9231 - val_sparse_categorical_accuracy: 0.1263\n",
      "Epoch 7/100\n",
      "271/272 [============================>.] - ETA: 5s - loss: 1.8846 - sparse_categorical_accuracy: 0.3301 \n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "272/272 [==============================] - 2029s 7s/step - loss: 1.8846 - sparse_categorical_accuracy: 0.3301 - val_loss: 3.9337 - val_sparse_categorical_accuracy: 0.1263\n",
      "Epoch 8/100\n",
      "272/272 [==============================] - 1898s 7s/step - loss: 1.8823 - sparse_categorical_accuracy: 0.3309 - val_loss: 3.9341 - val_sparse_categorical_accuracy: 0.1262\n",
      "Epoch 9/100\n",
      "271/272 [============================>.] - ETA: 4s - loss: 1.8818 - sparse_categorical_accuracy: 0.3310\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "272/272 [==============================] - 1845s 7s/step - loss: 1.8818 - sparse_categorical_accuracy: 0.3310 - val_loss: 3.9362 - val_sparse_categorical_accuracy: 0.1264\n",
      "Epoch 10/100\n",
      "272/272 [==============================] - 1854s 7s/step - loss: 1.8812 - sparse_categorical_accuracy: 0.3312 - val_loss: 3.9381 - val_sparse_categorical_accuracy: 0.1263\n",
      "Epoch 11/100\n",
      "271/272 [============================>.] - ETA: 4s - loss: 1.8811 - sparse_categorical_accuracy: 0.3313\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "272/272 [==============================] - 1849s 7s/step - loss: 1.8811 - sparse_categorical_accuracy: 0.3313 - val_loss: 3.9378 - val_sparse_categorical_accuracy: 0.1262\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b3ad96ca5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  tf.keras.models.Model(resnet_model.input, predictions)\n",
    "model.compile(tf.keras.optimizers.Adam(1e-4), loss = 'sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy'])\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "                        monitor='val_loss',\n",
    "                        min_delta=0,\n",
    "                        patience=10,\n",
    "                        verbose=1, \n",
    "                        mode='auto'\n",
    "                    )\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = 'val_loss',\n",
    "            patience=2,\n",
    "            factor=0.2,\n",
    "            verbose=1)\n",
    "\n",
    "\n",
    "model.fit(dg_train, validation_data = dg_valid, epochs  = 100, callbacks = [early_stopping_callback, reduce_lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = model.predict(dg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_arg = fc.argmax(axis = -1)\n",
    "\n",
    "for i in range(100):\n",
    "    fc_arg[fc_arg == i] = dg_test.bins_z[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_conv_ds = xr.Dataset({\n",
    "    'z': xr.DataArray(\n",
    "        fc_arg,\n",
    "        dims=['time', 'lat', 'lon'],\n",
    "        coords={'time':dg_test.data.time[72:], 'lat': dg_test.data.lat, 'lon': dg_test.data.lon,\n",
    "                })})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt, dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray ()&gt;\n",
       "array(959.12770532)\n",
       "Coordinates:\n",
       "    level    int32 500</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-3382fdfe-31cf-49b3-a8ff-dfc9e90917cf' class='xr-array-in' type='checkbox' checked><label for='section-3382fdfe-31cf-49b3-a8ff-dfc9e90917cf' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>959.1</span></div><div class='xr-array-data'><pre>array(959.12770532)</pre></div></div></li><li class='xr-section-item'><input id='section-f621ea0f-dc0c-4cb3-9a5c-d3b6a0462dc2' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f621ea0f-dc0c-4cb3-9a5c-d3b6a0462dc2' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>level</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>500</div><input id='attrs-78905340-4f37-4fdb-9d9e-eb26cd3974ef' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-78905340-4f37-4fdb-9d9e-eb26cd3974ef' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e1b65f3e-1b16-4044-875d-2db72e864e27' class='xr-var-data-in' type='checkbox'><label for='data-e1b65f3e-1b16-4044-875d-2db72e864e27' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>millibars</dd><dt><span>long_name :</span></dt><dd>pressure_level</dd></dl></div><div class='xr-var-data'><pre>array(500, dtype=int32)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-54c8049f-90cf-45a3-b2b5-5fbb67ba45f4' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-54c8049f-90cf-45a3-b2b5-5fbb67ba45f4' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray ()>\n",
       "array(959.12770532)\n",
       "Coordinates:\n",
       "    level    int32 500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.score import *\n",
    "\n",
    "compute_weighted_rmse(fc_arg, ds_test.z.sel(level=500)[72:]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b4edc7d4f60>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as plt\n",
    "plt.plot(fc[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test2]",
   "language": "python",
   "name": "conda-env-test2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
